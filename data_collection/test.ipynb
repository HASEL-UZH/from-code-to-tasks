{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T08:30:36.946861Z",
     "start_time": "2023-09-19T08:30:34.523542Z"
    }
   },
   "id": "ca720e6b9082bfeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings Code Diff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32f7453c6615a9b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_code_embeddings_added_deleted(codebert_model, added_code, deleted_code):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "    # Tokenize the added and deleted code\n",
    "    added_tokens = tokenizer(added_code)['input_ids']\n",
    "    deleted_tokens = tokenizer(deleted_code)['input_ids']\n",
    "\n",
    "    # Define the separator token ID (you need to obtain the correct ID from the tokenizer)\n",
    "    separator_token_id = tokenizer.convert_tokens_to_ids('<SEP>')  # Replace '<SEP>' with the correct separator token\n",
    "\n",
    "    # Concatenate added and deleted tokens with separator token in between\n",
    "    concatenated_tokens = added_tokens + [separator_token_id] + deleted_tokens\n",
    "\n",
    "    # Obtain code embeddings\n",
    "    code_embeddings = codebert_model(torch.tensor(concatenated_tokens)[None, :])[0]\n",
    "\n",
    "    return code_embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3daa459e433bb57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings Task Description"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6285886997599c9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_task_description_embeddings (codebert_model, task_description):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "    task_description_tokens = tokenizer(task_description)['input_ids']\n",
    "\n",
    "    # Concatenate added and deleted tokens with separator token in between\n",
    "    concatenated_tokens = task_description_tokens\n",
    "\n",
    "    # Obtain code embeddings\n",
    "    task_description_embeddings = codebert_model(torch.tensor(concatenated_tokens)[None, :])[0]\n",
    "\n",
    "    return task_description_embeddings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T08:30:36.953185Z",
     "start_time": "2023-09-19T08:30:36.950959Z"
    }
   },
   "id": "8625a75e93d05f5a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cosine Similarity Calculation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36d8b97e62b71321"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(code_embedding, task_description_embedding):\n",
    "\n",
    "    size_code_embedding = code_embedding.size()\n",
    "    size_task_description_embedding = task_description_embedding.size()\n",
    "\n",
    "    # truncate if necessary\n",
    "    if size_code_embedding.numel() < size_task_description_embedding.numel():\n",
    "        task_description_embedding = task_description_embedding[:, :size_code_embedding[1], :]\n",
    "\n",
    "    elif size_code_embedding.numel() > size_task_description_embedding.numel():\n",
    "        code_embedding = code_embedding[:, :size_task_description_embedding[1], :]\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    code_embedding_np = code_embedding.detach().numpy().reshape(1, -1)\n",
    "    task_description_embedding_np = task_description_embedding.detach().numpy().reshape(1, -1)\n",
    "\n",
    "    similarity = cosine_similarity(code_embedding_np, task_description_embedding_np)\n",
    "    similarity_value = similarity[0, 0]\n",
    "    return similarity_value\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T08:30:36.957214Z",
     "start_time": "2023-09-19T08:30:36.955221Z"
    }
   },
   "id": "ff3dbc67d74e1a26"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity correct: 0.70522225\n",
      "Cosine similarity incorrect: 0.76001275\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "added_code = 'ess.broadcastMessage(\"essentials.banip.notify\", tl(\"playerBanIpAddress\", senderName, ipAddress, banReason));'\n",
    "deleted_code = 'ess.broadcastMessage(\"essentials.ban.notify\", tl(\"playerBanIpAddress\", senderName, ipAddress, banReason));'\n",
    "task_description_correct = \"Silent ban messages?\"\n",
    "task_description_incorrect = \"Reduce permission check calls in PlayerCommandSendEvent\"\n",
    "\n",
    "code_embedding = create_code_embeddings_added_deleted(model, added_code, deleted_code)\n",
    "task_description_embedding_correct = create_task_description_embeddings(model, task_description_correct)\n",
    "task_description_embedding_incorrect = create_task_description_embeddings(model, task_description_incorrect)\n",
    "cosine_similarity_correct = calculate_cosine_similarity(code_embedding, task_description_embedding_correct)\n",
    "cosine_similarity_incorrect = calculate_cosine_similarity(code_embedding, task_description_embedding_incorrect)\n",
    "print(\"Cosine similarity correct:\", cosine_similarity_correct)\n",
    "print(\"Cosine similarity incorrect:\", cosine_similarity_incorrect)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T08:30:39.211880Z",
     "start_time": "2023-09-19T08:30:36.958355Z"
    }
   },
   "id": "5c2ff7645e073769"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T08:30:39.213718Z",
     "start_time": "2023-09-19T08:30:39.210906Z"
    }
   },
   "id": "2d6b0997f5febd1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3.9",
   "language": "python",
   "display_name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
